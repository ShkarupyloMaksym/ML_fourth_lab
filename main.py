# -*- coding: utf-8 -*-
"""fourth_lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n7ymujZP-qrFf_xI1nZ-0ciqspvgahUv

# Download with pip
"""

# !pip install --upgrade gdown

"""# Imports"""

import pandas as pd
import matplotlib.pyplot as plt
import os
import gdown
import re
from IPython.display import display
import numpy as np

from sklearn.model_selection import train_test_split, ShuffleSplit
# from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
import sklearn.metrics as skm
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

import seaborn as sns

"""# Constants"""

file_url = 'https://drive.google.com/file/d/1IVGHhWUq8ee5YNf0fdy1Rk1C3HXQgxb4/view?usp=drive_link'
data_file_name = 'data.csv'

"""# Some functions"""

def get_alphabet_position(letter):
    letter = letter.lower()
    alphabet = 'абвгґдеєжзиіїйклмнопрстуфхцчшщьюя'
    return alphabet.index(letter) + 1

def convert_drive_link(original_link):
  if "https://drive.google.com/uc?id=" in original_link:
    return original_link
  original_link = original_link.replace('?usp=sharing', '').replace('?usp=drive_link', '')
  pattern = r"https://drive\.google\.com/file/d/([a-zA-Z0-9_-]+)/view"

  matcher = re.match(pattern, original_link)

  if matcher:
    file_id = matcher.group(1)
    converted_link = f"https://drive.google.com/uc?id={file_id}"
    return converted_link
  else:
    raise Exception(f"Not realized Google Drive link format.\nGiven link is {original_link}")
    return None


def install_from_google_drive(link, name, path=None, force_download = False):
  full_path = name
  if path is not None:
    full_path = os.path.join(path, full_path)
  if not force_download:
    if os.path.exists(full_path):
      print('The data already exists')
      return

  print('Start downloading')
  gdown.download(convert_drive_link(link), full_path, quiet=False)
  print('\nDownloading have ended')

"""# Download data"""

install_from_google_drive(file_url, data_file_name)

"""# Task

## Constants
"""

n_splits = 10
chosen = 8

"""# 1. Відкрити та зчитати наданий файл з даними."""

df = pd.read_csv(data_file_name, sep=';')

df.head()

"""# 2. Визначити та вивести кількість записів."""

shape = df.shape
print(f'Кількість записів: {shape[0]}')

"""# 3. Вивести атрибути набору даних."""

pd.DataFrame(df.columns)

"""# 4. Отримати десять варіантів перемішування набору даних та розділення його на навчальну (тренувальну) та тестову вибірки, використовуючи функцію ***ShuffleSplit***. Сформувати начальну та тестові вибірки на основі восьмого варіанту. З’ясувати збалансованість набору даних."""

splited_indexes = ShuffleSplit(n_splits=n_splits, train_size=0.7, random_state=42)
train_index, test_index = [i for j, i in enumerate(splited_indexes.split(df)) if j == chosen-1][0]
train_df, test_df = df.loc[train_index], df.loc[test_index]

train_df['quality'].value_counts().to_frame().sort_index()

df.quality.unique()

"""# 5. Використовуючи функцію ***KNeighborsClassifier*** бібліотеки ***scikit-learn***, збудувати класифікаційну модель на основі методу k найближчих сусідів (значення всіх параметрів залишити за замовчуванням) та навчити її на тренувальній вибірці, вважаючи, що цільова характеристика визначається стовпчиком ***quality***, а всі інші виступають в ролі вихідних аргументів."""

x_train, y_train = train_df.iloc[:, :-1], train_df.iloc[:, -1]
x_test, y_test = test_df.iloc[:, :-1], test_df.iloc[:, -1]

# scaler = StandardScaler()
# pca = PCA(n_components=10) # empirical pseudo constant
# use_PCA = False
# def preprocess_df_post_split(df, do_fit=False):
#     if do_fit:
#         df = scaler.fit_transform(df)
#         if use_PCA:
#             df = pca.fit_transform(df)
#     else:
#         df = scaler.transform(df)
#         if use_PCA:
#             df = pca.transform(df)
#     return df

# x_train = preprocess_df_post_split(x_train, True)
# x_test = preprocess_df_post_split(x_test)

model = KNeighborsClassifier()
model.fit(x_train, y_train)

"""# 6. Обчислити класифікаційні метрики збудованої моделі для тренувальної та тестової вибірки. Представити результати роботи моделі на тестовій вибірці графічно."""

def show_prediction_results_deployed(model, x_test, y_test):
  y_predict = model.predict(x_test)
  data = pd.DataFrame(classification_report(y_test, y_predict, output_dict=True, )).T
  data = data.applymap(lambda x: round(x,4))

  display(data)
  sns.heatmap(confusion_matrix(y_test, y_predict), annot = True, fmt='.0f')

def get_model_metrics_sklearn(true_data, predicted):
  metrics = {'Accuracy': skm.accuracy_score,
             'Precision': lambda t, p: skm.precision_score(t, p, average='weighted'),
             'Recall': lambda t, p: skm.recall_score(t, p, average='weighted'),
             'F-Score': lambda t, p: skm.f1_score(t, p, average='weighted'),
             'Matthews Correlation Coefficient': skm.matthews_corrcoef,
             'Balanced Accuracy': skm.balanced_accuracy_score
             }
  for i in metrics:
      metrics[i] = [metrics[i](true_data, predicted)]
  return pd.DataFrame(metrics)

train_metrics = get_model_metrics_sklearn(y_train, model.predict(x_train))
test_metrics  = get_model_metrics_sklearn(y_test, model.predict(x_test))

train_metrics

test_metrics

n_metrics = len(train_metrics.columns)
index = np.array(range(n_metrics))

plt.figure(figsize=(10, 6))

bar_width = 0.35
opacity = 0.8

rects1 = plt.barh(index, train_metrics.loc[0], bar_width,
                  alpha=opacity,
                  color='black',
                  label='Train')

rects2 = plt.barh(index + bar_width, test_metrics.loc[0], bar_width,
                  alpha=opacity,
                  color='r',
                  label='Test')

plt.xlabel('Values')
plt.ylabel('Metrics')
plt.title('Model Metrics')
plt.yticks(index + bar_width / 2, train_metrics.columns)
plt.xlim(0, 1)
plt.legend()

plt.tight_layout()
plt.show()

show_prediction_results_deployed(model, x_test, y_test)

"""# 7. З’ясувати вплив кількості сусідів (від 1 до 20) на результати класифікації. Результати представити графічно."""

final_df = None
for n in range(1, 20+1):
  model_n = KNeighborsClassifier(n_neighbors=n)
  model_n.fit(x_train, y_train)
  new_df = get_model_metrics_sklearn(y_test, model_n.predict(x_test))
  new_df.loc[0, 'n'] = n
  final_df = pd.concat([final_df, new_df])

final_df

plt.figure(figsize=(10,6))
for n in final_df.columns:
  if n == 'n':
    continue
  plt.plot(final_df['n'], final_df[n], label=n)

plt.legend()
plt.xticks(range(1, 20+1))
plt.grid()
plt.ylim(0, 1)
plt.show()

